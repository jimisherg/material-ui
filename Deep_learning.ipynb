{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5OpLFG2d3VNvBgLExyQj8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimisherg/material-ui/blob/master/Deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multiprecacton Deepo Learning**"
      ],
      "metadata": {
        "id": "878o90x7zeOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kEeYfRd8zdLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "8l4Gbapi0jko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVwNyAt8MtkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "341d4959-effc-4133-b333-8de68809cb60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     CustomerID  HasAccount\n",
            "0             1           0\n",
            "1             2           1\n",
            "2             3           0\n",
            "3             4           0\n",
            "4             5           0\n",
            "..          ...         ...\n",
            "995         996           0\n",
            "996         997           0\n",
            "997         998           1\n",
            "998         999           1\n",
            "999        1000           0\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "import pandas as pd\n",
        "datasets = pd.read_csv(r\"/bank_customer_accounts.csv\")\n",
        "print(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "datasets"
      ],
      "metadata": {
        "id": "euHT6MHVz0_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = datasets.iloc[:,:-1]\n",
        "output_data = datasets.iloc[:,-1]\n",
        "ssl = StandardScaler()\n",
        "input_data = ssl.fit_transform(input_data)\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "TRyjolxa0Bl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/bank_customer_accounts.csv')  # Update the path to your CSV file\n",
        "\n",
        "# Splitting the data into input and output\n",
        "X = data[['CustomerID']]  # Input features\n",
        "y = data['HasAccount']     # Target variable\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=X_train.shape[1]))  # Input layer\n",
        "model.add(Dense(16, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "RtixHX8F3XJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/bank_customer_accounts.csv')  # Update the path to your CSV file\n",
        "\n",
        "# Assuming you have additional relevant features, you might include them as follows:\n",
        "# For this example, I'm adding hypothetical features\n",
        "# Replace this with your actual features in the dataset\n",
        "data['AccountBalance'] = np.random.uniform(1000, 10000, size=len(data))  # Hypothetical feature\n",
        "data['EstimatedSalary'] = np.random.uniform(30000, 150000, size=len(data))  # Hypothetical feature\n",
        "\n",
        "# Selecting features and target variable\n",
        "X = data[['CustomerID', 'AccountBalance', 'EstimatedSalary']]  # Input features\n",
        "y = data['HasAccount']     # Target variable\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))  # Increased neurons\n",
        "model.add(Dense(32, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)  # Increased epochs\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Optional: Print classification report for more insights\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)  # Convert probabilities to binary predictions\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTrXsyCV4C9h",
        "outputId": "6e21a347-32df-4f41-9049-89c43257910a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5026 - loss: 0.6971\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5122 - loss: 0.6927\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5347 - loss: 0.6857\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4979 - loss: 0.6902\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5328 - loss: 0.6858\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5618 - loss: 0.6840\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5388 - loss: 0.6873\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5498 - loss: 0.6844\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5574 - loss: 0.6851\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5548 - loss: 0.6879\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5719 - loss: 0.6815\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5363 - loss: 0.6848\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5777 - loss: 0.6847\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5183 - loss: 0.6881\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5549 - loss: 0.6823\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5559 - loss: 0.6820\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5323 - loss: 0.6874\n",
            "Epoch 18/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5503 - loss: 0.6835\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5645 - loss: 0.6829\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5499 - loss: 0.6852\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.6808\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5345 - loss: 0.6893\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.6748\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5673 - loss: 0.6799\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5677 - loss: 0.6774\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5255 - loss: 0.6867\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5615 - loss: 0.6826\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5564 - loss: 0.6795\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5464 - loss: 0.6781\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5899 - loss: 0.6717\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5674 - loss: 0.6800\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5698 - loss: 0.6735\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.6836\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5717 - loss: 0.6799\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5966 - loss: 0.6724\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5753 - loss: 0.6757\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5643 - loss: 0.6795\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5553 - loss: 0.6836\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.6670\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5779 - loss: 0.6719\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.6710\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5559 - loss: 0.6766\n",
            "Epoch 43/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.6763\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 0.6739\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.6738\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5339 - loss: 0.6874\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5705 - loss: 0.6690\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5707 - loss: 0.6814\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5702 - loss: 0.6774\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5624 - loss: 0.6761\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.6711\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.6718\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5596 - loss: 0.6756\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5474 - loss: 0.6822\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5890 - loss: 0.6706\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5766 - loss: 0.6676\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5997 - loss: 0.6620\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5861 - loss: 0.6686\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5766 - loss: 0.6667\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.6699\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5826 - loss: 0.6742\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5986 - loss: 0.6690\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5708 - loss: 0.6786\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.6713\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5705 - loss: 0.6721\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 0.6655\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 0.6626\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5801 - loss: 0.6702\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.6711\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 0.6732\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.6639\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5700 - loss: 0.6664\n",
            "Epoch 73/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.6647\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6015 - loss: 0.6625\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 0.6609\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5754 - loss: 0.6726\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.6696\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 0.6738\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5734 - loss: 0.6735\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5558 - loss: 0.6763\n",
            "Epoch 81/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5640 - loss: 0.6760\n",
            "Epoch 82/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5924 - loss: 0.6686\n",
            "Epoch 83/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 0.6700\n",
            "Epoch 84/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5949 - loss: 0.6661\n",
            "Epoch 85/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.6705\n",
            "Epoch 86/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5933 - loss: 0.6640\n",
            "Epoch 87/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5759 - loss: 0.6718\n",
            "Epoch 88/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 0.6726\n",
            "Epoch 89/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5848 - loss: 0.6643\n",
            "Epoch 90/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6155 - loss: 0.6622\n",
            "Epoch 91/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5931 - loss: 0.6701\n",
            "Epoch 92/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.6612\n",
            "Epoch 93/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5811 - loss: 0.6604\n",
            "Epoch 94/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 0.6659\n",
            "Epoch 95/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6192 - loss: 0.6473\n",
            "Epoch 96/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6196 - loss: 0.6561\n",
            "Epoch 97/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6209 - loss: 0.6550\n",
            "Epoch 98/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6078 - loss: 0.6584\n",
            "Epoch 99/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5978 - loss: 0.6632\n",
            "Epoch 100/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6194 - loss: 0.6546\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5235 - loss: 0.6843  \n",
            "Test Accuracy: 50.50%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.18      0.26        95\n",
            "           1       0.52      0.80      0.63       105\n",
            "\n",
            "    accuracy                           0.51       200\n",
            "   macro avg       0.48      0.49      0.44       200\n",
            "weighted avg       0.48      0.51      0.45       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/bank_customer_accounts.csv')  # Update the path to your CSV file\n",
        "\n",
        "# Hypothetical feature addition\n",
        "data['AccountBalance'] = np.random.uniform(1000, 10000, size=len(data))\n",
        "data['EstimatedSalary'] = np.random.uniform(30000, 150000, size=len(data))\n",
        "\n",
        "# Selecting features and target variable\n",
        "X = data[['CustomerID', 'AccountBalance', 'EstimatedSalary']]\n",
        "y = data['HasAccount']\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Balancing the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Splitting the balanced dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dropout(0.5))  # Adding dropout for regularization\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Adding another dropout layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Print classification report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmrSaEUb4o5Z",
        "outputId": "95218306-1874-4c78-c667-68579901fbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4958 - loss: 0.7156\n",
            "Epoch 2/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5102 - loss: 0.7029\n",
            "Epoch 3/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5217 - loss: 0.7014\n",
            "Epoch 4/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5129 - loss: 0.7010\n",
            "Epoch 5/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5277 - loss: 0.6957\n",
            "Epoch 6/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4932 - loss: 0.7058\n",
            "Epoch 7/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4825 - loss: 0.6936\n",
            "Epoch 8/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4643 - loss: 0.7013\n",
            "Epoch 9/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5094 - loss: 0.6933\n",
            "Epoch 10/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5057 - loss: 0.6968\n",
            "Epoch 11/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5271 - loss: 0.6927\n",
            "Epoch 12/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4903 - loss: 0.6953\n",
            "Epoch 13/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5135 - loss: 0.6876\n",
            "Epoch 14/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5039 - loss: 0.6950\n",
            "Epoch 15/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4885 - loss: 0.6931\n",
            "Epoch 16/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.6941\n",
            "Epoch 17/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5442 - loss: 0.6880\n",
            "Epoch 18/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4972 - loss: 0.6967\n",
            "Epoch 19/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.6995\n",
            "Epoch 20/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5052 - loss: 0.6931\n",
            "Epoch 21/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4801 - loss: 0.6960\n",
            "Epoch 22/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4722 - loss: 0.6943\n",
            "Epoch 23/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5146 - loss: 0.6927\n",
            "Epoch 24/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5376 - loss: 0.6946\n",
            "Epoch 25/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4914 - loss: 0.6949\n",
            "Epoch 26/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: 0.6924\n",
            "Epoch 27/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5527 - loss: 0.6904\n",
            "Epoch 28/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4888 - loss: 0.6941\n",
            "Epoch 29/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5147 - loss: 0.6927\n",
            "Epoch 30/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5234 - loss: 0.6922\n",
            "Epoch 31/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5362 - loss: 0.6892\n",
            "Epoch 32/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4991 - loss: 0.6922\n",
            "Epoch 33/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4772 - loss: 0.6937\n",
            "Epoch 34/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4891 - loss: 0.6967\n",
            "Epoch 35/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4924 - loss: 0.6945\n",
            "Epoch 36/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4982 - loss: 0.6967\n",
            "Epoch 37/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5070 - loss: 0.6944\n",
            "Epoch 38/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4831 - loss: 0.6960\n",
            "Epoch 39/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 0.6883\n",
            "Epoch 40/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5256 - loss: 0.6889\n",
            "Epoch 41/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4924 - loss: 0.6917\n",
            "Epoch 42/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5294 - loss: 0.6927\n",
            "Epoch 43/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4776 - loss: 0.6957\n",
            "Epoch 44/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5029 - loss: 0.6924\n",
            "Epoch 45/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5210 - loss: 0.6936\n",
            "Epoch 46/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5019 - loss: 0.6939\n",
            "Epoch 47/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5229 - loss: 0.6901\n",
            "Epoch 48/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5556 - loss: 0.6894\n",
            "Epoch 49/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5215 - loss: 0.6887\n",
            "Epoch 50/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4877 - loss: 0.6914\n",
            "Epoch 51/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5288 - loss: 0.6901\n",
            "Epoch 52/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5180 - loss: 0.6918\n",
            "Epoch 53/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4780 - loss: 0.6956\n",
            "Epoch 54/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4991 - loss: 0.6930\n",
            "Epoch 55/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5265 - loss: 0.6910\n",
            "Epoch 56/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5129 - loss: 0.6919\n",
            "Epoch 57/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5279 - loss: 0.6922\n",
            "Epoch 58/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5130 - loss: 0.6948\n",
            "Epoch 59/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4950 - loss: 0.6918\n",
            "Epoch 60/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5059 - loss: 0.6892\n",
            "Epoch 61/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5088 - loss: 0.6916\n",
            "Epoch 62/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5509 - loss: 0.6870\n",
            "Epoch 63/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4977 - loss: 0.6957\n",
            "Epoch 64/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5195 - loss: 0.6924\n",
            "Epoch 65/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5417 - loss: 0.6931\n",
            "Epoch 66/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5273 - loss: 0.6905\n",
            "Epoch 67/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5540 - loss: 0.6861\n",
            "Epoch 68/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5499 - loss: 0.6903\n",
            "Epoch 69/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5388 - loss: 0.6898\n",
            "Epoch 70/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4703 - loss: 0.6946\n",
            "Epoch 71/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 0.6902\n",
            "Epoch 72/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4955 - loss: 0.6932\n",
            "Epoch 73/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4768 - loss: 0.6957\n",
            "Epoch 74/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5405 - loss: 0.6909\n",
            "Epoch 75/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4884 - loss: 0.6940\n",
            "Epoch 76/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5400 - loss: 0.6881\n",
            "Epoch 77/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5237 - loss: 0.6916\n",
            "Epoch 78/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4982 - loss: 0.6938\n",
            "Epoch 79/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5248 - loss: 0.6935\n",
            "Epoch 80/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5544 - loss: 0.6884\n",
            "Epoch 81/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5337 - loss: 0.6930\n",
            "Epoch 82/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5429 - loss: 0.6934\n",
            "Epoch 83/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5065 - loss: 0.6917\n",
            "Epoch 84/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5021 - loss: 0.6922\n",
            "Epoch 85/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5014 - loss: 0.6938\n",
            "Epoch 86/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5024 - loss: 0.6906\n",
            "Epoch 87/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5259 - loss: 0.6889\n",
            "Epoch 88/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5161 - loss: 0.6959\n",
            "Epoch 89/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 0.6877\n",
            "Epoch 90/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 0.6878\n",
            "Epoch 91/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5220 - loss: 0.6891\n",
            "Epoch 92/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5257 - loss: 0.6911\n",
            "Epoch 93/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5272 - loss: 0.6885\n",
            "Epoch 94/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4874 - loss: 0.6955\n",
            "Epoch 95/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5197 - loss: 0.6899\n",
            "Epoch 96/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 0.6884\n",
            "Epoch 97/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5269 - loss: 0.6880\n",
            "Epoch 98/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5031 - loss: 0.6912\n",
            "Epoch 99/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5148 - loss: 0.6949\n",
            "Epoch 100/100\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5598 - loss: 0.6858\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5298 - loss: 0.6962  \n",
            "Test Accuracy: 51.47%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.20      0.30       106\n",
            "           1       0.50      0.86      0.63        98\n",
            "\n",
            "    accuracy                           0.51       204\n",
            "   macro avg       0.55      0.53      0.46       204\n",
            "weighted avg       0.55      0.51      0.46       204\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizing the target variable\n",
        "sns.countplot(data['HasAccount'])\n",
        "plt.title('Distribution of HasAccount')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "6-Fgq5Ny49qB",
        "outputId": "8653983d-e299-47d6-e379-030a7b2aef29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/bank_customer_accounts.csv')  # Update the path to your CSV file\n",
        "\n",
        "# Preprocessing\n",
        "data['AccountBalance'] = np.random.uniform(1000, 10000, size=len(data))\n",
        "data['EstimatedSalary'] = np.random.uniform(30000, 150000, size=len(data))\n",
        "\n",
        "X = data[['CustomerID', 'AccountBalance', 'EstimatedSalary']]\n",
        "y = data['HasAccount']\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))  # Input layer\n",
        "model.add(Dropout(0.5))  # Dropout layer\n",
        "model.add(Dense(64, activation='relu'))  # Hidden layer\n",
        "model.add(Dropout(0.5))  # Dropout layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Optional: Print classification report for more insights\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usraU5T45rXi",
        "outputId": "ca6e1768-f9c9-4d47-c3ce-eff63667695c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.4895 - loss: 0.6986 - val_accuracy: 0.5562 - val_loss: 0.6906\n",
            "Epoch 2/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4935 - loss: 0.7136 - val_accuracy: 0.5437 - val_loss: 0.6921\n",
            "Epoch 3/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5495 - loss: 0.6985 - val_accuracy: 0.5188 - val_loss: 0.6933\n",
            "Epoch 4/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5202 - loss: 0.6937 - val_accuracy: 0.5188 - val_loss: 0.6922\n",
            "Epoch 5/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5319 - loss: 0.6948 - val_accuracy: 0.4812 - val_loss: 0.6971\n",
            "Epoch 6/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5222 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 7/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5104 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6938\n",
            "Epoch 8/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5186 - loss: 0.6977 - val_accuracy: 0.4812 - val_loss: 0.6960\n",
            "Epoch 9/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5559 - loss: 0.6885 - val_accuracy: 0.4750 - val_loss: 0.6944\n",
            "Epoch 10/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 0.6911 - val_accuracy: 0.4688 - val_loss: 0.6981\n",
            "Epoch 11/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5257 - loss: 0.6950 - val_accuracy: 0.4812 - val_loss: 0.7006\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4827 - loss: 0.7019  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce79ce18e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 52.00%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.58      0.53        95\n",
            "           1       0.55      0.47      0.51       105\n",
            "\n",
            "    accuracy                           0.52       200\n",
            "   macro avg       0.52      0.52      0.52       200\n",
            "weighted avg       0.52      0.52      0.52       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/bank_customer_accounts.csv')  # Update the path to your CSV file\n",
        "\n",
        "# Hypothetical features\n",
        "data['AccountBalance'] = np.random.uniform(1000, 10000, size=len(data))\n",
        "data['EstimatedSalary'] = np.random.uniform(30000, 150000, size=len(data))\n",
        "\n",
        "# Selecting features and target variable\n",
        "X = data[['CustomerID', 'AccountBalance', 'EstimatedSalary']]\n",
        "y = data['HasAccount']\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))  # Increased neurons\n",
        "model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
        "model.add(Dense(64, activation='relu'))  # Hidden layer\n",
        "model.add(Dropout(0.5))  # Another dropout layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=10, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Optional: Print classification report for more insights\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1J_xsBk56TH",
        "outputId": "413dae18-97a5-421c-f7e4-ba788665d59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.4915 - loss: 0.7116 - val_accuracy: 0.4187 - val_loss: 0.7024\n",
            "Epoch 2/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4906 - loss: 0.7045 - val_accuracy: 0.4625 - val_loss: 0.7050\n",
            "Epoch 3/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5002 - loss: 0.6997 - val_accuracy: 0.4625 - val_loss: 0.7050\n",
            "Epoch 4/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5366 - loss: 0.6910 - val_accuracy: 0.4688 - val_loss: 0.7013\n",
            "Epoch 5/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5383 - loss: 0.6937 - val_accuracy: 0.4750 - val_loss: 0.7044\n",
            "Epoch 6/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5723 - loss: 0.6881 - val_accuracy: 0.4500 - val_loss: 0.7056\n",
            "Epoch 7/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5537 - loss: 0.6920 - val_accuracy: 0.4375 - val_loss: 0.7071\n",
            "Epoch 8/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5206 - loss: 0.6885 - val_accuracy: 0.4500 - val_loss: 0.7053\n",
            "Epoch 9/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5454 - loss: 0.6928 - val_accuracy: 0.4437 - val_loss: 0.7053\n",
            "Epoch 10/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5542 - loss: 0.6855 - val_accuracy: 0.4500 - val_loss: 0.7071\n",
            "Epoch 11/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5647 - loss: 0.6770 - val_accuracy: 0.4500 - val_loss: 0.7075\n",
            "Epoch 12/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5192 - loss: 0.7066 - val_accuracy: 0.4688 - val_loss: 0.7039\n",
            "Epoch 13/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5458 - loss: 0.6884 - val_accuracy: 0.4688 - val_loss: 0.7039\n",
            "Epoch 14/200\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5297 - loss: 0.6935 - val_accuracy: 0.4625 - val_loss: 0.7030\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5559 - loss: 0.6909  \n",
            "Test Accuracy: 55.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce79eb04f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.38      0.44        95\n",
            "           1       0.56      0.70      0.62       105\n",
            "\n",
            "    accuracy                           0.55       200\n",
            "   macro avg       0.55      0.54      0.53       200\n",
            "weighted avg       0.55      0.55      0.54       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/bank_customer_accounts.csv')  # Update the path to your CSV file\n",
        "\n",
        "# Hypothetical features\n",
        "data['AccountBalance'] = np.random.uniform(1000, 10000, size=len(data))\n",
        "data['EstimatedSalary'] = np.random.uniform(30000, 150000, size=len(data))\n",
        "\n",
        "# Selecting features and target variable\n",
        "X = data[['CustomerID', 'AccountBalance', 'EstimatedSalary']]\n",
        "y = data['HasAccount']\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))  # Increased neurons\n",
        "model.add(Dropout(0.5))  # Dropout layer\n",
        "model.add(Dense(64, activation='relu'))  # Hidden layer\n",
        "model.add(Dropout(0.5))  # Another dropout layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=10, validation_split=0.2,\n",
        "          callbacks=[early_stopping, reduce_lr], verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Optional: Print classification report for more insights\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh0dKJXt6M1F",
        "outputId": "5e15fdd2-0449-4f93-9cb9-74ff65fae935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5380 - loss: 0.7010 - val_accuracy: 0.4437 - val_loss: 0.7020 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5263 - loss: 0.7011 - val_accuracy: 0.4437 - val_loss: 0.7004 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4598 - loss: 0.7124 - val_accuracy: 0.4563 - val_loss: 0.6978 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5193 - loss: 0.6982 - val_accuracy: 0.4812 - val_loss: 0.7008 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5575 - loss: 0.6845 - val_accuracy: 0.4563 - val_loss: 0.7006 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4996 - loss: 0.7007 - val_accuracy: 0.4812 - val_loss: 0.7002 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5227 - loss: 0.6925 - val_accuracy: 0.4688 - val_loss: 0.7028 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5235 - loss: 0.6842 - val_accuracy: 0.4563 - val_loss: 0.7016 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5009 - loss: 0.6941 - val_accuracy: 0.4750 - val_loss: 0.7015 - learning_rate: 5.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5624 - loss: 0.6847 - val_accuracy: 0.4437 - val_loss: 0.7030 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5655 - loss: 0.6882 - val_accuracy: 0.4500 - val_loss: 0.7034 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4956 - loss: 0.6975 - val_accuracy: 0.4437 - val_loss: 0.7024 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5659 - loss: 0.6769 - val_accuracy: 0.4500 - val_loss: 0.7037 - learning_rate: 5.0000e-04\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5039 - loss: 0.6932  \n",
            "Test Accuracy: 48.00%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.53      0.49        95\n",
            "           1       0.51      0.44      0.47       105\n",
            "\n",
            "    accuracy                           0.48       200\n",
            "   macro avg       0.48      0.48      0.48       200\n",
            "weighted avg       0.48      0.48      0.48       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/bank_customer_accounts.csv')  # Update the path to your CSV file\n",
        "\n",
        "# Hypothetical features\n",
        "data['AccountBalance'] = np.random.uniform(1000, 10000, size=len(data))\n",
        "data['EstimatedSalary'] = np.random.uniform(30000, 150000, size=len(data))\n",
        "\n",
        "# Selecting features and target variable\n",
        "X = data[['CustomerID', 'AccountBalance', 'EstimatedSalary']]\n",
        "y = data['HasAccount']\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Adjusted dropout rate\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=10, validation_split=0.2,\n",
        "          callbacks=[early_stopping, reduce_lr], verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Optional: Print classification report and confusion matrix for more insights\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DC4UyiQ6e5u",
        "outputId": "60fce947-9f64-475e-94a4-8b05048e82fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5184 - loss: 0.9972 - val_accuracy: 0.5188 - val_loss: 0.6927 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5226 - loss: 0.7391 - val_accuracy: 0.4750 - val_loss: 0.7021 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5476 - loss: 0.7116 - val_accuracy: 0.5125 - val_loss: 0.6975 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5341 - loss: 0.7251 - val_accuracy: 0.4750 - val_loss: 0.6981 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5198 - loss: 0.7358 - val_accuracy: 0.5125 - val_loss: 0.6926 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5163 - loss: 0.7087 - val_accuracy: 0.4875 - val_loss: 0.6924 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5552 - loss: 0.7060 - val_accuracy: 0.5375 - val_loss: 0.7051 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5853 - loss: 0.6731 - val_accuracy: 0.4750 - val_loss: 0.7034 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5788 - loss: 0.6921 - val_accuracy: 0.4688 - val_loss: 0.7121 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4833 - loss: 0.7143 - val_accuracy: 0.4625 - val_loss: 0.7261 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 0.6709 - val_accuracy: 0.4812 - val_loss: 0.7025 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5892 - loss: 0.6874 - val_accuracy: 0.4625 - val_loss: 0.7049 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5574 - loss: 0.6931 - val_accuracy: 0.4688 - val_loss: 0.7064 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5545 - loss: 0.6944 - val_accuracy: 0.4812 - val_loss: 0.7087 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5257 - loss: 0.6941 - val_accuracy: 0.4875 - val_loss: 0.7039 - learning_rate: 5.0000e-04\n",
            "Epoch 16/300\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5097 - loss: 0.7010 - val_accuracy: 0.4625 - val_loss: 0.7064 - learning_rate: 5.0000e-04\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5391 - loss: 0.7012  \n",
            "Test Accuracy: 53.50%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.55      0.53        95\n",
            "           1       0.56      0.52      0.54       105\n",
            "\n",
            "    accuracy                           0.54       200\n",
            "   macro avg       0.54      0.54      0.53       200\n",
            "weighted avg       0.54      0.54      0.54       200\n",
            "\n",
            "[[52 43]\n",
            " [50 55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sumNlMNT6tWW",
        "outputId": "db1a17d8-9860-45cb-fe9e-1f33ed6c6541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.5142 - loss: 0.9485 - val_accuracy: 0.5610 - val_loss: 0.6879 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5095 - loss: 0.8089 - val_accuracy: 0.5549 - val_loss: 0.6919 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4556 - loss: 0.8339 - val_accuracy: 0.4695 - val_loss: 0.7007 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5127 - loss: 0.7639 - val_accuracy: 0.4512 - val_loss: 0.7054 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5165 - loss: 0.7227 - val_accuracy: 0.5061 - val_loss: 0.6940 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5240 - loss: 0.7548 - val_accuracy: 0.5183 - val_loss: 0.6965 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4994 - loss: 0.7274 - val_accuracy: 0.5305 - val_loss: 0.6950 - learning_rate: 5.0000e-04\n",
            "Epoch 8/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5116 - loss: 0.7264 - val_accuracy: 0.5366 - val_loss: 0.6973 - learning_rate: 5.0000e-04\n",
            "Epoch 9/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5399 - loss: 0.7084 - val_accuracy: 0.5183 - val_loss: 0.6992 - learning_rate: 5.0000e-04\n",
            "Epoch 10/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4802 - loss: 0.7513 - val_accuracy: 0.5244 - val_loss: 0.6986 - learning_rate: 5.0000e-04\n",
            "Epoch 11/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5720 - loss: 0.7063 - val_accuracy: 0.5183 - val_loss: 0.7021 - learning_rate: 5.0000e-04\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5238 - loss: 0.6964 \n",
            "Test Accuracy: 51.96%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.68       106\n",
            "           1       0.00      0.00      0.00        98\n",
            "\n",
            "    accuracy                           0.52       204\n",
            "   macro avg       0.26      0.50      0.34       204\n",
            "weighted avg       0.27      0.52      0.36       204\n",
            "\n",
            "[[106   0]\n",
            " [ 98   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EcnyNMS88ZWc",
        "outputId": "d2f159d2-cfc9-43a6-99a1-f01da5fdfb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     CustomerID  HasAccount\n",
              "0             1           0\n",
              "1             2           1\n",
              "2             3           0\n",
              "3             4           0\n",
              "4             5           0\n",
              "..          ...         ...\n",
              "995         996           0\n",
              "996         997           0\n",
              "997         998           1\n",
              "998         999           1\n",
              "999        1000           0\n",
              "\n",
              "[1000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-855a998c-fa95-4f90-b145-c8e4213a9ab3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>HasAccount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>996</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>997</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>998</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-855a998c-fa95-4f90-b145-c8e4213a9ab3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-855a998c-fa95-4f90-b145-c8e4213a9ab3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-855a998c-fa95-4f90-b145-c8e4213a9ab3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f78cb9ce-7fd8-46d0-91e4-dbca0b4c5a9c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f78cb9ce-7fd8-46d0-91e4-dbca0b4c5a9c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f78cb9ce-7fd8-46d0-91e4-dbca0b4c5a9c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e94aa502-eeb5-4464-8b9d-dec06f65416d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e94aa502-eeb5-4464-8b9d-dec06f65416d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"CustomerID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 1,\n        \"max\": 1000,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          522,\n          738,\n          741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HasAccount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/bank_customer_accounts.csv')  # Update the path to your CSV file\n",
        "\n",
        "# Display the first few rows to understand the data\n",
        "print(data.head())\n",
        "\n",
        "# Drop CustomerID as it's not useful for training\n",
        "data.drop('CustomerID', axis=1, inplace=True)\n",
        "\n",
        "# Select features and target variable\n",
        "X = data.drop('HasAccount', axis=1)  # Features (all columns except target)\n",
        "y = data['HasAccount']  # Target variable\n",
        "\n",
        "# If you don't have other features, you can create some dummy features for training purposes\n",
        "# Here, I'm adding random values for demonstration; replace this with actual feature engineering as needed\n",
        "X['AccountBalance'] = np.random.uniform(1000, 10000, size=len(data))  # Example feature\n",
        "X['EstimatedSalary'] = np.random.uniform(30000, 150000, size=len(data))  # Example feature\n",
        "\n",
        "# Handle class imbalance if necessary\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Standardizing the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_resampled)\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))  # Increased dropout for regularization\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))  # Increased dropout for regularization\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=10, validation_split=0.2,\n",
        "          callbacks=[early_stopping, reduce_lr], verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Optional: Print classification report and confusion matrix for more insights\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)  # Convert probabilities to binary predictions\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5Tjjld_9SfC",
        "outputId": "c5831b54-79f2-4051-8a14-83a9551b0f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CustomerID  HasAccount\n",
            "0           1           0\n",
            "1           2           1\n",
            "2           3           0\n",
            "3           4           0\n",
            "4           5           0\n",
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5151 - loss: 0.8693 - val_accuracy: 0.5610 - val_loss: 0.6858 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5154 - loss: 0.7683 - val_accuracy: 0.5610 - val_loss: 0.6900 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 0.7249 - val_accuracy: 0.5610 - val_loss: 0.6918 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4910 - loss: 0.7524 - val_accuracy: 0.5549 - val_loss: 0.6912 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5202 - loss: 0.7318 - val_accuracy: 0.5610 - val_loss: 0.6845 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4919 - loss: 0.7293 - val_accuracy: 0.5671 - val_loss: 0.6909 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4980 - loss: 0.7392 - val_accuracy: 0.5122 - val_loss: 0.6948 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4747 - loss: 0.7292 - val_accuracy: 0.5244 - val_loss: 0.6987 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5190 - loss: 0.7118 - val_accuracy: 0.4573 - val_loss: 0.7148 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5090 - loss: 0.7467 - val_accuracy: 0.5305 - val_loss: 0.7118 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4687 - loss: 0.7467 - val_accuracy: 0.5366 - val_loss: 0.7060 - learning_rate: 5.0000e-04\n",
            "Epoch 12/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4968 - loss: 0.7088 - val_accuracy: 0.5061 - val_loss: 0.7087 - learning_rate: 5.0000e-04\n",
            "Epoch 13/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5492 - loss: 0.6980 - val_accuracy: 0.5000 - val_loss: 0.7063 - learning_rate: 5.0000e-04\n",
            "Epoch 14/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4977 - loss: 0.7173 - val_accuracy: 0.5183 - val_loss: 0.7050 - learning_rate: 5.0000e-04\n",
            "Epoch 15/300\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5194 - loss: 0.7338 - val_accuracy: 0.5122 - val_loss: 0.7013 - learning_rate: 5.0000e-04\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5525 - loss: 0.6884 \n",
            "Test Accuracy: 54.90%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.92      0.68       106\n",
            "           1       0.64      0.14      0.23        98\n",
            "\n",
            "    accuracy                           0.55       204\n",
            "   macro avg       0.59      0.53      0.46       204\n",
            "weighted avg       0.59      0.55      0.47       204\n",
            "\n",
            "[[98  8]\n",
            " [84 14]]\n"
          ]
        }
      ]
    }
  ]
}